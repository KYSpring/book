# AI 3.0
## 总结

- 书的定位：
  
  人工智能（artificial intelligence, AI）类的图书可谓汗牛充栋，大致可分为两类：一类是给专业的工程师看的，另一类是给大众的普及读物。米歇尔的这部书介乎两者之间，它有专业的技术阐释，更有深刻的思想洞察。

  人工智能的种种讨论，特别是涉及技术伦理、社会价值和发展前景的时候，人们一般只会停留在悲观或者乐观的选边站队层面，无法进一步深入下去。这不奇怪，技术专家们擅长的话语是数据、算法、模型，社会学者和新闻记者们只能从技术的外部性、代码的背后之手、人性之善恶的角度，捍卫或者批判某种价值主张。对绝大多数非专业人士而言，由于搞不懂隐藏在反向传播算法、卷积神经网络（convolutional neural networks，ConvNets）、马尔可夫过程、熵原理这些硬核知识背后的思想内涵，就只能以“好与坏”“善与恶”的视角对人工智能进行理解和评判。

- 关于AI的元议题：（关键问题整理）
https://docs.qq.com/mind/DZWtpV0pzV0R6VFVB

1. 人工智能技术的底层逻辑是什么？
   
   米歇尔将其总结为“从更好的猜测中学习猜测“；
   
   - 目标函数原理
 
    举个例子，比如玩蒙眼点鼻子的游戏。蒙眼人拿着笔走向一幅大鼻子卡通画，然后摸索着去点画中的鼻子。如果有个声音不停地提示其偏离的方向，蒙眼人就可以很快地点中鼻子。这个提示点鼻子的偏差的信息，对蒙眼人点中鼻子至关重要。想象让机器来完成这个任务，机器可以不理解什么是鼻子，什么是点，也不用明白这么做有什么娱乐的价值，但如果能给出判断点中与否的目标函数，就可以大大提高机器成功完成任务的概率。

   - 蒙特卡洛原理
    
    今天的机器算法，固然已经在棋类博弈中完胜人类棋手，但从智能角度看，与那时相比其实并无实质性的进步。也就是说，无论机器的自学能力有多强，有一件事是确定的，即游戏目标的存在。游戏规则和游戏目标作为先验知识，给出了这样一个明确的博弈边界，即这一游戏的博弈空间是有穷空间。算法的唯一目标就是赢，不管其对手是人还是另一个机器算法，也不管对弈双方是否理解游戏，或者能否欣赏游戏之美，它只追求赢。使算法可以获知距离获胜还有多远，使用的是蒙特卡洛方法，只要确保最优策略依然在剩下的搜索空间里就好，换句话说，比对手多预测几步就有更大的胜算。

2. 人工智能是在模拟思考，还是真的在思考？

  - 世界是“隐喻式”的
  
  这个世界是隐喻式的，我们并非确凿无疑地生活在符号世界中，我们生活在色彩斑斓的隐喻中。固然不同的文化所对应的底层逻辑之间难以互通或相互转化，甚至不同的文化隐喻所导致的生活信念彼此抵牾，但人类仍然有共享的元认知（metacognition），这一元认知是维系多样化世界的最后屏障。

  - GPT-3根本不懂自然语言，它只是很快而已

  GPT-3可以写论文、小说，起草格式合同，甚至大批量生产段子。但也有评论不客气地指出，GPT-3根本不懂自然语言，它只是很快而已。对于目前的自然语言项目，它们其实毫无“理解”可言，它们唯一的本领就是“见多识广”。问题在于，虽然一款智能机器可以快速遍历状态空间的更多可能性，把边边角角都扫描到。但理解的基础是意义，意义是人工智能的真正障碍。至于这一障碍是否不可逾越，这可以成为激烈争论的话题。米歇尔所阐述的意义问题，并不是说人工智能无法理解意义，也不是说人工智能无法创造出新的意义，而是说，人工智能对意义的理解是否在安全边界之内——这其实也是全书开篇提到的“侯世达的恐惧”的核心内容。

  - 再论“图灵测试”

  图灵曾给出了这样的建议：“‘机器会思考吗’这个问题应该被替换为‘是否存在可想象的数字计算机能够在图灵测试中表现出色’。”换句话说，如果一台计算机足够像人类，以致难以与人类区分（除了它的外表、声音、气味和感觉等），我们为什么不能认为它是在真正地思考呢？为什么我们非得要求一个实体必须是用某种特殊的物质（如生物细胞）创建出来的，才承认其处于“思考”的状态呢？
  
3. 人工智能方法论有哪些流派？
   
   - 先是歌德尔证明了不完备定理，接着图灵提出了图灵机，并将计算的本质归于机械的操作，进而约翰·冯·诺依曼（John von Neumann）建立了数字计算机的逻辑操作结构。自此，我们有了现代计算机，并开始了人工智能研究，成就了今日之信息产业“旧”IT（information technology，信息技术），目前，已开始迈向智能产业“新”IT（intelligent technology，智能技术）
   - 从邱奇-图灵论题（Church-Turing thesis）开始，在诺依曼有意无意的引导下，学界关于智能的思考和认识逐渐形成了两个派别：“图灵派”和“歌德尔派”。
   - 图灵派本质上是计算主义，认为基于简单规则的计算可以涌现出复杂的行为和智能。从物理符号系统的逻辑智能到联结主义的计算智能，这一思想主导了人工智能至今的发展历史，是构建智能系统的主要理论和方法源泉。
   - 歌德尔认为，存在先于可计算的不可计算，即存在不可计算的客观存在。存在不可计算的物理、生命和数学过程，且计算机不能真正理解语言和想象等相关的活动。因此根本没有构建智能的一般规律和方法，而且现有的一些规律和方法不应成为第一性的，只有动因和信念才是本质，接受现状继续演化是发展人工智能的唯一途径。

4. 机器是否将最终取代人类？

   - 20世纪50年代之前，英文中“computer”一词其实是指从事计算工作的人类，但今天作为机器的“computer”已经完全代替了作为人类的“computer”；然而，被称为“computer”的机器，不但没有使人类大规模失业，而且还为人类创造了更好、更多的新工作，比如程序员、架构师、算法工程师、网络管理员，等等。事实胜于“恐”辩，尽管机器可能造成一定程度的短暂的社会错位，使一些人失去工作，但不会造成人类的大规模失业，相反，机器能够创造出更多、更好、适合人类的工作，推动社会进步。
   - 这就是著名的“杰文斯悖论”（Jevons paradox）：技术进步可以提高人力资源的利用效率，但结果是增加而不是减少社会对人力资源的需求，因为效率的提高将导致生产规模的扩大。
   - 威廉姆·斯坦利·杰文斯（William Stanley Jevons）是19世纪英国的数学家、哲学家和经济学家，现代经济学中的边际效用理论的主要奠基人。

5. 人工智能领域的泡沫为何循环不断？
   
   人工智能领域的泡沫不断产生又破灭这种循环的一个早期例子。这一循环是这样运转的：

   - 第一阶段，新想法在研究领域得到了大量的支持。相关研究人员承诺人工智能即将取得突破性的成果，并被新闻媒体各种炒作。政府资助部门和风险投资者向学术研究界和商业初创公司注入大量资金。
   - 第二阶段，曾经承诺的人工智能突破没有如期实现，或者远没有当初承诺的那么令人满意。政府资助和风险资本枯竭，初创公司倒闭，人工智能研究放缓。
  
    研究人工智能的群体已经熟悉了这一模式：先是“人工智能的春天”，紧接着是过度的承诺和媒体炒作，接下来便是“人工智能的寒冬”。从某种程度上来说，这一现象以5～10年为周期在不断上演。

6. 现实世界的“长尾效应”该如何解决？

   - “长尾”这个术语来自统计学，其中包含的一长串可能性低，但却可能发生的情况被称为一个概率分布的“尾巴”。
   - 如果我们单纯依靠监督学习来提升人工智能系统对世界的认识，那么就会存在一个问题：尾部的情况并不经常出现在训练数据中，所以当遇到这些意外情况时，系统就会更容易出错。

7. “侯世达的恐惧”：我们是应该担心人工智能变得太聪明，还是担心人工智能太容易取代我们人类所珍视的东西？
   
   侯世达是被“音乐智能实验”（Experiments in Musical Intelligence，EMI）的优美创作吓坏了，他曾这样说道：“我被EMI吓坏了，完全吓坏了。我厌恶它，并感受到了极大的威胁——人工智能对我最珍视之人性的威胁。我认为EMI是我对人工智能感到恐惧的最典型的实例。”

   我们应该感到害怕，不是害怕机器太智能，而是害怕机器做出一些它们没有能力做出的决策。相比于机器的“智能”，我更害怕机器的“愚笨”。机器的愚笨会创造一个尾部风险。机器可以做出很多好的决策，然后某天却会因为在其训练数据中没有出现过的一个尾部事件而迅速失灵，这就是特定智能和通用智能的区别。正如人工智能研究人员佩德罗·多明戈斯说的那段令人印象深刻的话：“人们担心计算机会变得过于聪明并接管世界，但真正的问题是计算机太愚蠢了，并且它们已经接管了世界。”
   

   

## 《AI 3.0》笔记导出

梅拉妮·米歇尔
189个笔记

第五章 序

◆ 人工智能（artificial intelligence, AI）类的图书可谓汗牛充栋，大致可分为两类：一类是给专业的工程师看的，另一类是给大众的普及读物。米歇尔的这部书介乎两者之间，它有专业的技术阐释，更有深刻的思想洞察。

◆ 人工智能的种种讨论，特别是涉及技术伦理、社会价值和发展前景的时候，人们一般只会停留在悲观或者乐观的选边站队层面，无法进一步深入下去。这不奇怪，技术专家们擅长的话语是数据、算法、模型，社会学者和新闻记者们只能从技术的外部性、代码的背后之手、人性之善恶的角度，捍卫或者批判某种价值主张。对绝大多数非专业人士而言，由于搞不懂隐藏在反向传播算法、卷积神经网络（convolutional neural networks，ConvNets）、马尔可夫过程、熵原理这些硬核知识背后的思想内涵，就只能以“好与坏”“善与恶”的视角对人工智能进行理解和评判。

◆ 《AI 3.0》开篇即提出这样一个“侯世达的恐惧”：不是担心人工智能太聪明，而是担心人工智能太容易取代我们人类所珍视的东西。这说出了很多人的

◆ DeepMind创始人之一沙恩·莱格（Shane Legg）认为，超越人类水平的人工智能将在2025年左右出现。谷歌公司战略委员会成员雷·库兹韦尔（Ray Kurzweil）(2)则提出了令人震惊的“奇点理论”，他认为2029年完全通过图灵测试（Turing test）的智能机器将会出现，以强人工智能为基础的智能爆炸将会在2045年出现。
米歇尔的论述有一条清

◆ 局面的能力，机器必须进入更大的对弈空间，这就是强化学习的含义。如理查德·萨顿（Richard Sutton）所言，强化学习就是“从猜测中学习猜测”，米歇尔将其调整为“从更好的猜测中学习猜测

◆ 的人工智能，往往在速度上卓尔不凡，因为它可以动辄在更大的博弈空间里处理海量的数据，表现出令人咋舌的算力水平，远远超过人类的计算能力。这种能力在让人惊艳的同时，也带有很强的迷惑性，使人误以为机器已经“沾了仙气”，比如IBM的智能机器沃森就是如此。其实这是假象，如今的人工智能，与真正的人工智能之间依然有巨大的鸿沟。什么是真正的人工智能？业界对其定义也一直争论不休，这里暂且不论。

◆ 目标函数是什么？举个例子，比如玩蒙眼点鼻子的游戏。蒙眼人拿着笔走向一幅大鼻子卡通画，然后摸索着去点画中的鼻子。如果有个声音不停地提示其偏离的方向，蒙眼人就可以很快地点中鼻子。这个提示点鼻子的偏差的信息，对蒙眼人点中鼻子至关重要。想象让机器来完成这个任务，机器可以不理解什么是鼻子，什么是点，也不用明白这么做有什么娱乐的价值，但如果能给出判断点中与否的目标函数，就可以大大提高机器成功完成任务的概率。
其实，当下

◆ 使算法可以获知距离获胜还有多远，他们使用的是蒙特卡洛方法，只要确保最优策略依然在剩下的搜索空间里就好，换句话说，比对手多预测几步就有更大的胜算。
从游戏中学习套路，人工智

◆ 0年内机器必然战胜人类。今天的机器算法，固然已经在棋类博弈中完胜人类棋手，但从智能角度看，与那时相比其实并无实质性的进步。也就是说，无论机器的自学能力有多强，有一件事是确定的，即游戏目标的存在。游戏规则和游戏目标作为先验知识，给出了这样一个明确的博弈边界，即这一游戏的博弈空间是有穷空间。算法的唯一目标就是赢，不管其对手是人还是另一个机器算法，也不管对弈双方是否理解游戏，或者能否欣赏游戏之美，它只追求赢。

◆ 因此，机器在零和博弈空间里完胜人类这一点，并非凸显了机器智能超群，只是进一步验证了人类的局限性和零和博弈目标的有限性。除此之外，机器所取得的成功说明不了更多。
从视觉系统和游

◆ 还不止这些，GPT-3还可以写论文、小说，起草格式合同，甚至大批量生产段子。当然，也有评论不客气地指出，GPT-3根本不懂自然语言，它只是很快而已。它的确太快了，据说它有1 750亿个参数，我们姑且认为它可以处理如此巨量的参数

◆ 对于目前的自然语言项目，我可以武断地说，它们其实毫无“理解”可言，它们唯一的本领就是“见多识广”。问题在于，虽然一款智能机器可以快速遍历状态空间的更多可能性，把边边角角都扫描到，然

◆ 。她指出，理解的基础是意义，意义是人工智能的真正障碍。至于这一障碍是否不可逾越，这可以成为激烈争论的话题。我感觉，米歇尔所阐述的意义问题，并不是说人工智能无法理解意义，也不是说人工智能无法创造出新的意义（当然这取决于你怎么定义“意义”），而是说，人工智能对意义的理解是否在安全边界之内——这其实也是全书开篇提到的“侯世达的恐惧”的核心内容。
为了便于大家理解

◆ 。意义的产生，既有漫长、深厚、难以细数的生活积淀，以及约定俗成的“能指-所指”的任意配对，也有突破词语边界的“类比”和“象征”，按米歇尔的导师侯世达的观点，这种类比和象征是“思考之源和思维之火”。


◆ 米歇尔提出了一个根本性的问题：人工智能是否以及何时能打破意义的障碍？
米歇尔并未直截了当地回答这个艰难的问题，但她毕竟是侯世达的学生，她从侯世达的思想中汲取营养：这个世界是隐喻式的，我们并非确凿无疑地生活在符号世界中，我们生活在色彩斑斓的隐喻中。固然不同的文化所对应的底层逻辑之间难以互通或相互转化，甚至不同的文化隐喻所导致的生活信念彼此抵牾，但人类仍然有共享的元认知（metacognition），这一元认知是维系多样化世界的最后屏障。


◆ 人工智能所面临的“硬核”问题，并不在于机器和人谁控制谁，而在于机器成长的过程意味着什么，机器将如何成长，什么时候会变得强大，强大之后机器会是什么样子。

◆ 天才的工程师、创新公司的CEO（首席执行官）虽然也会思考这类问题，但他们更愿意先干起来再说。硅谷的很多公司信奉的准则是：预测未来最好的办法就是把它造出来。

◆ 可怕的恰恰是工程师忘记了“意义”问题其实远远超出人类目前的认知边界。


◆ 智能机器的存在和成长，是否会拓展人类的元认知，将这一元认知拓展为人机共享的元认知？仅靠文字的思维方式，可能难以走出符号演算的“如来佛之掌”。侯世达在40多年前写作“GEB”的时候，针对人工智能提出了10个问题并给出了自己的答案，侯世达对这10个问题的思考，更多地指向形式逻辑、符号演算和线性思维天然的不足之处，这一不足之处正在于：符号思维难以超越其内生的逻辑悖论。


◆ 需要看到的是，这种旧世界的世界观属于符号世界。人工智能底层思维的突破，关键可能就在于：超越这一旧世界的束缚，将婆罗门世界观中的因明(3)思想与中国春秋战国时期的名辩(4)思想以及古希腊的逻格斯(5)思想，在更大的框架下融合起来，这是一个伟大的挑战。


◆ 第三波人工智能浪潮已经大大突破了前两波人工智能浪潮在思想上的束缚，在哲学范式上捅开了一个突破口，不只是符号表征、计算问题，更多的是意义问题。


第六章 译者序

◆ 世达是被“音乐智能实验”（Experiments in Musical Intelligence，EMI）的优美创作吓坏了，他曾这样说道：“我被EMI吓坏了，完全吓坏了。我厌恶它，并感受到了极大的威胁——人工智能对我最珍视之人性的威胁。我认为EMI是我对人工智能感到恐惧的最典型的实例。”我曾听说过侯世达对人工智能的担忧，但当时不以为然，我认为一个对人工智能了解如此之深、认识如此之深刻的学者不应过度害怕智能技术。

◆ 在“GEB”一书的最后，侯世达曾列出关于人工智能的“十大问题和猜想”，其中第一个就是关于音乐的。那时他认为计算机可以谱写出优美的音乐，但并不会很快实现，因为音乐是一种关于情感的语言，在程序能够拥有我们人类所拥有的这种复杂的情感之前，它绝无可能谱写出任何优美的作品。


◆ 歌德尔证明了不完备定理，接着图灵提出了图灵机，并将计算的本质归于机械的操作，进而约翰·冯·诺依曼（John von Neumann）建立了数字计算机的逻辑操作结构。自此

◆ 邱奇-图灵论题（Church-Turing thesis）开始，在诺依曼有意无意的引导下，学界关于智能的思考和认识逐渐形成了两个派别：“图灵派”和“歌德尔派”

◆ 歌德尔认为，存在先于可计算的不可计算，即存在不可计算的客观存在。存在不可计算的物理、生命和数学过程，且计算机不能真正理解语言和想象等相关的活动。研究人工智能的第一位华人学者王浩晚年曾致力于歌德尔的思想与哲学的研究，他总结道：“歌德尔认为机器不可能超越人脑，除非数学不是人类发明的。而且，就算数学不是人类发明的，机器还是无法超越人脑。”


◆ ，即智能分为算法智能（algorithmic intelligence，AI）、语言智能（linguistic intelligence，LI）和想象智能（imaginative intelligence，II）三个层面，算法智能无法超越语言智能，语言智能又无法超越想象智能。正如歌德尔在普林斯顿高等研究院的同事爱因斯坦所言：“智能的真正标识不是知识，而是想象。”

◆ 哲学家伏尔泰曾说：“定义你的术语……否则我们将永远无法相互理解。”然而，前文的讨论使我们认识到，即便有了

◆ 正如哲学家黑格尔所揭示的：历史给我们的教训是，人们从来都不知道汲取历史的教训。实际上，人类在过去100多年内至少经历了三次这种担心，这就是“老”“旧”“新”三次IT变革。当年，人们对老IT（工业技术）的担心远大于今

◆ 70多年前，诺伯特·维纳的控制论和数字计算机的出现开启了旧IT（信息技术）的变革，又一次引发社会对机器取代人类工作的担心。为此，维纳还发表了《人有人的用处》（The Human Use of Human Beings）来专门讨论这一问题，其中特别强调“信息永远不能取代启迪”（Information will never replace illumination.）。

◆ 今天作为机器的“computer”已经完全代替了作为人类的“computer”；然而，被称为“computer”的机器，不但没有使人类大规模失业，而且还为人类创造了更好、更多的新工作，比如程序员、架构师、算法工程师、网络管理员，等等。事实胜于“恐”辩，尽管机器可能造成一

◆ 这就是著名的“杰文斯悖论”（Jevons paradox）。威廉姆·斯坦利·杰文斯（William Stanley Jevons）是19世纪英国的数学家、哲学家和经济学家，现代经济学中的边际效用理论的主要奠基人。在英国工业革命时期，工业大量消耗煤资源并产生了严重的污染，引发了利用技术提高燃煤效率的讨论，但杰文斯的研究表明：烧煤效率越高，耗煤量将会越大。这就是杰文斯悖论：技术进步可以提高自然资源的利用效率，但结果是增加而不是减少人们对这种资源的需求，因为效率的提高会导致生产规模的扩大，这会进一步刺激需要。


◆ 计算机的“机器取代人”的例子说明广义的杰文斯悖论也成立：技术进步可以提高人力资源的利用效率，但结果是增加而不是减少社会对人力资源的需求，因为效率的提高将导致生产规模的扩大。

◆ 向人机混合、虚实交互的平行智能（AI 3.0）迈进。


◆ 我们不是不相信智能技术，我们只是不相信智能技术背后的人类。

◆ 人类社会发展的历史告诉我们，随着技术的发展，我们需要越来越多的法务工作者。将来，或许罪犯会非常少，但“智警”或“法务工程师”会成为智慧社会的重要从业人员，远多于普通的警察和法官。这


第七章 引言

◆ 侯世达认为，从原则上讲，人工智能是有可能实现的：“它的‘敌人’是那些说人工智能不可能实现的人，比如约翰·瑟尔（John Searle）、休伯特·德雷福斯（Hubert Dreyfus）以及其他怀疑论者。他们不理解大脑是一堆服从物理定律的物质，也不理解计算机

◆ 可以模拟任何东西，更不用说神经元、神经递质等层面的内容了。从理论上讲，这是可以实现的。”实际上，

◆ AI 3.0》这本书不是关于人工智能的综述或历史，确切地说，它是对一些人工智能方法的深入探索，这些方法可能正在影响或者即将影响我们的生活。本书还将论述那些在挑战我们人类独特性方面发展程度最高的人工智能成就。写


第九章 01 从起源到遭遇寒冬，心智是人工智能一直无法攻克的堡垒

◆ 在1956年，即便是最先进的计算机，其速度也达不到现代智能手机的百万分之一，但麦卡锡和他的同事依旧非常乐观地认为人工智能是触手可及的：“我们认为，只要精心挑选一组科学家共同针对这其中的一个或多个课题研究一整个夏天，就能够取得重大的进展。”5
然而很快就出现

◆ ，明斯基创造了“手提箱式词汇”（suitcase word）11这一术语，其意思是：每个词语就像是打包封装了不同含义的手提箱。人工智能就经过了“打包”，在不同的上下文中承担不同的含义。

◆ 数学家提倡将数学逻辑和演绎推理作为理性思维的语言；另一些人则支持归纳法，这是一种运用程序从数据中提取统计特征，并使用概率来处理不确定性的方法；其他人则坚信应该从生物学和心理学中汲取灵感来创造类似大脑的程序

◆ 感知学习算法，无法重现人脑的涌现机制

◆ 正确的行为时奖励，而在犯错时惩罚。如今，这种形式的条件计算在人工智能领域被称为监督学习（supervised learning）。在训练时，给定学

◆ 纽约时报》对罗森布拉特于1958年7月组织的一次新闻发布会的报道，做出了如下说明：
今天，美国海军公布了一款预计能走路、说话、看东西、写字、自我复制，并能够意识到自我存在的电子计算机的雏形。据估计，感知机不久后就将能够识人，并叫出他们的名字，还能将一种语言的语音即时翻译成另外一种语言的语音和文字18。
是的，即便是刚出现的时候，人工智能就已在面临炒作的问题。稍后我将多讨论一些由这种炒作造成的不好的结果。

◆ 是人工智能领域的泡沫不断产生又破灭这种循环的一个早期例子。这一循环是这样运转的：
·　第一阶段，新想法在研究领域得到了大量的支持。相关研究人员承诺人工智能即将取得突破性的成果，并被新闻媒体各种炒作。政府资助部门和风险投资者向学术研究界和商业初创公司注入大量资金。
·　第二阶段，曾经承诺的人工智能突破没有如期实现，或者远没有当初承诺的那么令人满意。政府资助和风险资本枯竭，初创公司倒闭，人工智能研究放缓。
研究人工智能的群体已经熟悉了这一模式：先是“人工智能的春天”，紧接着是过度的承诺和媒体炒作，接下来便是“人工智能的寒冬”。从某种程度上来说，这一现象以5～10年为周期

◆ 对于任何谈论人工智能的人来说，定义“人工智能”都是一个挑战，因为人工智能的核心概念——智能，仍然没有明晰的定义。针对类似“智能”及其引申词，如“思想”“认知”“意识”“情感”这样的词语，明斯基创造了“手提箱式词汇”这一术语，其意思是：每个词语就像是打包封装了不同含义的手提箱。人工智能就经过了“打包”，在不同的上下文中承担不同的含义。
大多数人会认同人类是智能的，而尘埃颗


第一十章 02 从神经网络到机器学习，谁都不是最后的解药

◆ 20世纪80年代，最引人注目的神经网络研究小组是加州大学圣迭戈分校的一个团队，由心理学家大卫·鲁梅尔哈特（David Rumelhart）和詹姆斯·麦克莱兰德（James McClelland）带领。我们现在所说的神经网络，在当时一般被称作“联结主义网络”，其中“联结主义”（connectionist）这个术语指的是：这些网络上的知识存在于单元之间的加权连接中。

◆ 1986年出版，名为《并行分布式处理》（Parallel Distributed Processing）。在由符号人工智能主导的人工智能版图中，这本书为亚符号化研究方法的支持者鼓舞了士气，并提出了这样的观点：“人类比当今的计算机更聪明，是因为人的大脑采用了一种更适合于人类完成他们所擅长的自然信息处理任务的基本计算架构，例如，‘感知’自然场景中的物体并厘清它们之间的关系……理解语言，并从记忆中检索上下文恰当的信息。”4该书的作者推测：明斯基和佩珀特所青睐的这类符号系统是无法获得这些人类所拥有的能力的5。



第一十一章 03 从图灵测试到奇点之争，我们无法预测智能将带领我们去往何处

◆ 人工智能的议论突然变多了，商界注意到了这一点。许多大型科技公司都在人工智能的研发上投入了数十亿美元，他们要么直接聘用人工智能的专家，要么收购规模较小的初创公司，而唯一的目的就是挖走这些公司里的杰出人才，也就是所谓的“人才收购”。被“收购”的潜在可能性加上可能迅速成为百万富翁的希望，使初创企

◆ 人工智能是在模拟思考，还是真的在思考
这类哲学问题从一开始就一直困扰着人工智能领域的研究者。在20世纪30年代就勾勒出了第一个可编程计算机框架的英国数学家艾伦·图灵，于1950年发表的论文《计算机器与智能》（Computing Machinery and Intelligence）中提出了这样一个问题：“当我们问‘机器能思考吗？’，我们到底是要表达什么意思？”在提出著名的“模仿游戏”（imitation game，现在称为图灵测试，稍后会详细介绍）之后，图灵列出了对一台实际会思考的机器之前景的9条可能的反对意见，并试图反驳这9条意见

◆ 如果一台机器能够写出一首十四行诗或一首协奏曲，是因为它感受到的思想和情感，而不是因为符号的偶然组合，只有这样，我们才会认同该机器等同于大脑。也就是说，它不仅写出来了，而且知道自己写出来了。没有机器能够为自己的成功而感到快乐、为自己的开关被关上而感到悲伤、为受到称赞而感到温暖、因为犯错而感到痛苦、对性感兴趣、为自己想要却得不到某样东西感到愤怒或沮丧。其他的人工信号或简单的发明也做不到以上这些事情

◆ 母亲：我不知道。我认为关于思考，存在一种永远无法被计算机完全模仿的人类特性。
我的

◆ 结果似乎更多地揭示了关于裁判和测试本身的一些问题，而不是机器

◆ 出于这些原因，大多数人工智能专家都很讨厌图灵测试，至少到目前为止是这样。他们将此类测试视为宣传噱头，认为其结果与人工智能的进步毫无关系。虽

◆ ，库兹韦尔都是人工智能乐观主义学派的领头人。他是马文·明斯基在麻省理工学院的学生，也是一个杰出的发明家：他发明了第一台将文本转为语音的机器，以及世界上最好的音乐合成器。为此，1999年，美国总统比尔·克林顿授予了库兹韦尔美国国家技术创新奖章。

◆ 他作为未来学家的预测，最著名的就是他提出的“奇点”的概念：“在未来的某个时期，技术变革的步伐将如此之快，影响将如此之深，以至于人类生活将被不可逆转地改变。

◆ 认识的大多数人都有类似的怀疑。对人工智能的主流态度在记者莫琳·多德（Maureen Dowd）的一篇文章中得到了完美体现，她描述了她与斯坦福大学的著名人工智能研究者吴恩达（Andrew Ng）的一次对话，在她提到库兹韦尔时，吴恩达条件反射性地翻了个白眼，并说道：“每当我读到库兹韦尔的《奇点临近》时，我的眼睛就会不受控制地做出这种反应。”33


第一十三章 04 何人，何物，何时，何地，为何

◆ ，但ConvNets实际上并不是很新，最初是在20世纪80年代由法国计算机科学家杨立昆提出，而他则是受到了福岛提出的神经认知机的启发。杨立昆是ConvNets之父，纽约大学终身教授，深度学习三巨头之一，杨立昆是他给自己起的中文名字。



第一十四章 05 ConvNets和ImageNet，现代人工智能的基石

◆ WordNet已经并将继续被心理学家和语言学家广泛应用于科学研究以及人工智能自然语言处理系统之中，但李飞飞有一个新的想法：根据WordNet中的名词构建一个图像数据库，使其中每个名词都与大量包含该名词示例的图像相关联。因此ImageNet的构想诞生

◆ 所需的人类智能。该网站有一个奇怪的名字：“亚马逊土耳其机器人”（Amazon Mechanical Turk）。

◆ 。土耳其机器人的出现正体现了明斯基所说的“容易的事情做起来难”，人类被雇用来执行目前对计算机来说仍然很难的“简单”任务。

◆ 土耳其机器人的名字来自一个发生在18世纪的著名的人工智能骗局：原始版本的土耳其机器人是一个玩国际象棋的“智能机器”，其实是一个人秘密地藏在其中来控制木偶下棋，这个木偶即“土耳其机器人”，其穿着打扮就像奥斯曼帝国的苏丹。它愚弄了当时的许多知名人士，包括拿破仑·波拿巴。亚马逊的这项服务，其目的不是愚弄任何人，就像最初的土耳其机器人一样，它只是一种“人工的”人工智能

◆ 2010年得分最高的程序使用了所谓的“支持向量机”算法，这是当时主流的目标识别算法，它运用复杂的数学知识来学习如何为每个输入图像分配类别

◆ 平稳上升的趋势在2012年的ImageNet竞赛中陡然改变了：获奖程序top-5准确率达到了惊人的85%，这种准确率的飞跃实在是令人震惊的进步。更令人吃惊的是，获胜的程序并没有使用支持向量机算法或当时其他主流的计算机视觉算法，而是使用的ConvNets。这个独特的ConvNets名为AlexNet，以其主要开发者亚历克斯·克里泽夫斯基（Alex Krizhevsky）的

◆ 盛大的“ImageNet竞赛2015”围绕着不到一个百分点的差距展开，这看似微不足道的差距却潜藏着丰厚的利润。2015年年初，百度的一个团队公布了一种方法，在ImageNet测试集上达到了有史以来最高的top-5准确率——94.67%，但就在同一天，微软的一个团队宣称他们的方法取得了更高的准确率：95.06%。几天后，来自谷歌的一只竞争队伍宣布他们使用了一种稍微不同的方法，其识别效果更好，准确率为95.18%

◆ 让我们更深入地分析一下有关计算机如今在ImageNet上的目标识别能力是否已经超越人类的具体争论。这一论断是基于人类的错误率约为5%，而机器的错误率接近2%的一个声明，这难道无法证明计算机在这项任务上的表现比人类更好吗？与其他人工智能的高调宣传中经常出现的情况一样，这一声明也存在一些注意事项。

◆ 下面要说的第三个注意事项可能会让你大吃一惊。当一个人说，照片中有一条狗时，我们认为这是因为人类在图像中实际上看到了一条狗，但是如果ConvNets“说”图像中有狗时，我们如何确定它真的是基于图像中包含狗这一判断来进行输出的呢？也许图像中有一些其他对象，如网球、飞盘、被叼住的鞋子，这些对象在训练图像中往往与狗相关，而ConvNets在识别这些对象时就会假设图像中有一条狗。这类关联的结果往往会愚弄程序，使其做出误判。

◆ 同时还要学会在目标对象周围画一个方框，这样我们就知道机器确实“看到”了目标。这就是ImageNet竞赛后来启动实施的“定位挑战赛”

◆ 我们离真正的视觉智能还非常遥远

◆ 如果计算机视觉的目标是让机器描述它“看到”的内容，那么机器不仅需要识别目标，还需要识别目标之间的关系以及目标如何与世界交互。如果问题情境中的目标是生物，机器将需要了解它们的行动、目标、情感、可能的后续行为，以及讲述视觉场景中发生的故事所包含的其他所有方面的内容；而且，如果我们真的希望机器描述它所“看到”的内容，它们将需要使用语言。人工智能研究者正在积极争取让机器能做这些事情，但像往常一样，这些看似“容易”的事情做起来非常困难。正如计算机视觉专家阿里·法尔哈迪（Ali Farhadi）在接受《纽约时报》的采访时所说的那样，“我们距离真正实现能够像人类那样理解场景和动作的视觉智能还非常非常遥远”15。

◆ 本章要点
0


第一十五章 06 人类与机器学习的关键差距

◆ 自己来之不易的经验中获取它。正如微软研究院主任埃里克·霍维茨（Erik Horvitz）所说：“现在，我们所研究的不是一门科学，而是一种炼金术。”5根据DeepMind的联合创始人戴米斯·哈萨比斯（Demis Hassabis）的说法，这些能做到“网络低语”（network whispering）(22)的人们形成了一个小型且排外的群体，“这几乎是一种集各种系统之优点为一体的艺术形式……世界上只有几百人能够真正做好这项工作”6。


◆ 约书亚·本吉奥（Yoshua Bengio）表示赞同，他说：“实事求是地讲，我们不可能对世界上的所有事物都进行标注，并一丝不苟地把每一个细节都解释给计算机听

◆ 凯特·克劳福德（Kate Crawford）是微软的一名研究员，同时也是一名致力于实现人工智能公平性和透明性的活动家。她指出：一个被广泛使用的、用于训练人脸识别系统的数据集包含了77.5%的男性和83.5%的白人面孔。

◆ ，人工智能训练数据中的这些偏见反映了我们社会中的偏见，但在这些有偏见的数据集上训练的人工智能系统，如果在真实世界的应用中传播开来，就能够放大这些偏见并造成真正的危害。例如

◆ 《麻省理工科技评论》（MIT Technology Review）杂志将这种不可理解性称为“人工智能内心的黑暗秘密”19。令人担忧的是：如果我们不理解DNN如何解答问题，我们就无法真正相信它们，或预测它们会在哪种情况下出错。

◆ 目前人工智能界最热门的新兴领域之一是“可解释的人工智能”，也就不足为奇了。这个新领域有多种不同的叫法，比如“透明的人工智能”或“可解释的机器学习”。这个领域的目标是研究如何让人工智能

◆ DNN可能面临的一种对抗式攻击：以一种人类难以察觉但却会引发网络改变对图像的分类的方式来改变X射线或显微镜图像，是不难做到的，但却可能会导致网络对该图像的判定完全相反，比如说，从以99%置信度显示目标图像分类为无癌症，到以99%置信度显示存在癌症26。该

◆ 计算机安全的任何领域一样，到目前为止的研究具有一种“打地鼠”的特点，即一个安全漏洞被检测出来并被成功防御后，总是会发现新的需要防御的漏

◆ 团队的人工智能专家伊恩·古德费洛（Ian Goodfellow）说道：“几乎所有你能想到的对一个机器学习模型有害的事，都可以在当下就做到……捍卫它真的是非常非常困难

◆ 怀俄明大学的人工智能研究者杰夫·克卢恩（Jeff Clune）做了一个非常尖锐的比喻：“很多人好奇深度学习究竟是真正的智能还是‘聪明的汉斯’。”28汉斯是20世纪初德国的一匹马，其主人声

◆ “聪明的汉斯”已成为对表现出理解力但实际上只是对训练员给出的别人难以发现的提示做出反应的个体或程序的隐喻。深度学习展现的是真正的理

◆ 一情况由于长尾效应的存在而进一步恶化：

◆ “长尾”这个术语来自统计学，其中包含的一长串可能性低，但却可能发生的情况被称为一个概率分布的“尾巴

◆ 如果我们单纯依靠监督学习来提升人工智能系统对世界的认识，那么就会存在一个问题：尾部的情况并不经常出现在训练数据中，所以当遇到这些意外情况时，系统就会更容易出错。


第一十六章 07 确保价值观一致，构建值得信赖、有道德的人工智能

◆ 人脸识别的伦理困境

◆ FaceFirst公司。据《新科学家》（New Scientist）杂志报道：“FaceFirst正在面向零售商推出一套系统，据称这套系统可以通过识别每次购物的高价值客户来进行促销，而当多次被投诉的顾客进入任何一家门店时，该系统就会发出警报。”6还有许多其他公司提供类似的服务。

◆ 我认为对人工智能的监管应该参照其他领域的技术监管，尤其是那些在生物和医学领域的技术，例如基因工程。在这些领域，像质量保证、技术的风险和收益分析这样的监管是通过政府机构、公司、非营利性组织和大学之间的合作而产生的。此外，现在已经建立了生物伦理学和医学伦理学领域，这些领域对技术的研发和应用方面的决策具有相当大的影响。人工智能领域的研究及其应用非常需要深思熟虑的考量和一定的道德基础。
这个基础已经开始形成。

◆ 自从人们开始思考人工智能，就开始了关于“机器道德”问题的思考14。也许，关于机器道德的最著名的讨论来自艾萨克·阿西莫夫（Isaac Asimov）的科幻小说，他在小说中提出了著名的“机器人三定律”1

◆ 科幻小说家亚瑟·克拉克（Arthur C. Clarke）在其1968年出版的《2001：太空漫游》16中描写了一个类似的情节。人工智能计算机HAL被编程为始终对人类保持诚实，但同时又要对人类宇航员隐瞒他们的太空任务的真实目的。与阿西莫夫的笨拙的机器人不同，HAL饱受这种认知失调的心理痛苦的折磨：“他意识到隐瞒真相与保持忠诚之间的这种冲突正在慢慢地破坏他的心智。”17结果是，这种计算机“神经症”使HAL变成了一名杀手


第一十八章 08 强化学习，最重要的是学会给机器人奖励

◆ 有关珍奇动物驯兽师的书后，她了解到，驯兽师最重要的驯兽方法其实非常简单：奖励其正确的行为，忽略其不正确的行为。并且，就像她在《纽约时报》的“现代爱情”专栏上写的那样：“最终这使我想到，这一相同的技巧在倔强而可爱的‘物种’——丈夫身上可能也会起作用。”萨瑟兰描写了在经过多年徒劳的唠叨、讽刺和抱怨之后，她如何用这个简单的方法来悄悄地训练她那健忘的丈夫去收拾自己的袜子、找到车钥匙、准时到餐厅赴约以及更有规律地刮胡子1。
这种经典的训练技

◆ 操作性条件反射使得一种重要的机器学习方法——强化学习得

◆ 强化学习的愿景是：智能体（如机器狗）能够通过在现实世界中执行一些动作并偶尔获得奖励（即强化）的方式来自主地学习灵活的策略，而无须人类手动编写规则或直接“教育”智能体如何应对各种可


第一十九章 09 学会玩游戏，智能究竟从何而来

◆ 完成对底层每个棋局的评估，也就是前瞻过程结束后，程序就会使用一个被称为“极小化极大”（minimax）的经典算法，来对程序从当前棋局走出的下一步棋的所有可能性进行评估，然后选择其中评分最

◆ 尽管塞缪尔的西洋跳棋程序是人工智能历史上的一个重要里程碑

◆ 则不同了。用哈萨比斯的话来说：“几十年来，顶尖的计算机科学家都相信，因为国际象棋被看作人类智力的典型印证，所以一个精通国际象棋的计算机游戏程序将会很快在其他方面全面超越人类

◆ 还有对人类今后是否还有下棋动力的怀疑，但是自深蓝出现后的这么多年里，人类已经渐渐适应了这一情况。正如香农在1950年有预见性地写道：“一台能在国际象棋上超越人类的机器将迫使我们要么承认机械化思维的可能性，要么进一步限制我们对‘思维’这一概念的理解。”17如今，后者已经发生了。

◆ 意义，它也没有任何概念。我曾听一位演讲者打趣道：“深蓝确实打败了卡斯帕罗夫，但它从未从中获得任何乐趣

◆ 18
围棋，规则简单却能产生无穷的复杂性
围棋已有两千多年的历史，被公认为所有棋类游戏中最难的。如果你不是一位围棋棋手，也不用担心，这里的任何讨论并不要求有围棋的先验知识，但要知道这一游戏的地位很高，尤其是在东亚，围棋非常受欢迎。学者兼记者艾伦·列维诺夫（Alan Levinovitz）曾这样写道：“围棋是帝王将相、知识分子和天才少年所钟爱的消遣。”他继而引用了韩国围棋冠军李世石（Lee Sedol）的一句话：“西方世界有国际象棋，但围棋有着其不可比拟的精妙和智慧。”19
围棋是一款规则相当简单但却能产生近乎无穷复杂性的游戏。在每个回合中，棋手将己方所执颜色的棋子（黑棋或白棋）按照落子和提子规则放置在一块19×19的正方形棋盘上。与国际象棋中兵、象、王后这种层级结构不同的是，围棋中的棋子都是平等的。棋手需要根据棋子在棋盘上的布局进行快速分析并决定下一步行棋。

◆ 蒙特卡洛树搜索启动的值。
凭借其AlphaGo项目，DeepMind证明了：人工智能领域中长期以来的重大挑战之一，能够被强化学习、ConvNets和蒙特卡洛树搜索，以及在这一组合中加入的强大的现代计算硬件所体现出的创造性征服。因此，AlphaGo在人工智能“万神殿”中有着当之无愧的地位。但接下来呢？这种强大的组合方法能被泛化并应用到游戏之外的世界中去吗？这是我们在下一

◆ 理查德·萨顿是这种方法的鼻祖之一，他把该方法称为：从猜测中学习猜测。我把它修改为：从更好的猜测中学习猜测。简而言之，强化学习不是将其输出与人类给定的标签进行比较，而是假设后续迭代给出的值比前面迭代给出的值更好，网络学习的是使其输出在一次迭代到下一次迭代的过程中保持一致。


第二十章 10 游戏只是手段，通用人工智能才是目标

◆ 机器学习领域，有一个充满前景的学习方法，那就是“迁移学习”（transfer learning），它是指一个程序将其所学的关于一项任务的知识进行迁移，以帮助其获得执行不同的相关任务的能力。对于人类来说，迁移学习是自动进行的，比如，我在学会打乒乓球之后，就能将其中的一些技巧进行迁移来帮助我学习打网球和羽毛球；知道如何下西洋跳棋，也有助于我学习国际象棋；当我还是个孩童的时候，学习如何转动我房间的门把手是花费了一些时间的，但是当我掌握了这个技能后，我的这种能力就迅速地泛化到几乎所有的门把手上了

◆ DeepMind的声明中有一句话需要考量——即便是在最具挑战性的领域。我们如何能够评估某个领域对人工智能的挑战性？正如我们已经看到的，许多我们人类认为相当容易的事情，例如，描述一张照片的内容，对计算机来说却极具挑战性。相反，许多对于我们人类来说极其艰难的事情，例如，正确地将两个50位的数字相乘，计算机却可以用一行代码在瞬间完成。

◆ ，人类玩的许多游戏甚至比围棋更具挑战性。马库斯给出的一个示例是猜字谜游戏8，如果你仔细想想，你会发现：这个游戏需要远超任何现有人工智能系统的复杂的视觉、语言和社会理解能力。如果你能制造出一个可以像6岁的小孩那样玩猜字谜游戏的机器人，那么我认为你可以很有把握地说，你已经征服了多个对人工智能来说最具挑战性的领域。

◆ 系统没有学会这样的东西，它并不真正理解什么是隧道、什么是墙，它仅仅学会了针对特定场景的应变措施。迁移测试表明深度强化学习的解决方案通常极端肤浅。在迁移测试中，深度强化学习系统所面临的场景与其在训练时所面临的场景仅存在细微的不同，然而，系统都无法通过测试

◆ AlphaGo是人工智能领域的一项伟大成就，主要通过自我对弈进行学习，并且能够在一场经典的智力角逐类的比赛中击败世界上最杰出的人类棋手之一。可是，AlphaGo并没有表现出通常意义上的人类水平的智能，甚至没有表现出任何真正的智能。对于人类来说，智能的一个关键点并非在于能够学习某一特定的技能，而在于能够学会思考，并且可以灵活地将这种思考能力用于应对任何可能遇到的情况或挑战，这也是我们希望孩子们能够通过下国际象棋或围棋学习到的真正技能。从这个意义上讲，学校的国际象棋或围棋俱乐部里最低年级的小朋友都比AlphaGo聪明得多。


第二十二章 11 词语，以及与它一同出现的词

◆ 针对如何将单词放置在语义空间中的问题，研究者提出了许多解决方案，有些方案甚至可以追溯到20世纪80年代，但如今最为广泛采用的方法是谷歌的研究团队在2013年提出的13。谷歌的研究人员称他们的方法为“单词到向量”（word to vector, word2vec）。word2vec方法的工作原理是使用传统的神经网络来自动学习词汇表中的所有单词的词向量。谷

◆ 这里我们可以这样来类比：对于一个手里拿着锤子的人来说，所有事情看起来都像一颗钉子；对于一个专注神经网络的人工智能研究员来说，所有事情看起来都像一个向量。许多人由此想到：word2vec方法不仅可以用于单个词，还可以用于整个句子，为什么不把整个句子编码为一个向量呢？与编码词的方法一样，在训练过程中使用句子对而非单词对，不就可以了吗？用这样的方式来获取语义不是比简单地使用一组词向量更好吗？事实上，的确有一些研究团队做过这方面的尝试：多伦多大学的一个团队将这些语句称为“思维向量”（thought vectors）20，还有人尝试过用网络将段落和整个文档编码为向量，然而结果都是成败参半。

◆ 谷歌的杰弗里·辛顿宣称：“我们可以用一个向量来捕捉一个想法。”21Facebook的杨立昆表示赞同：“在Facebook的人工智能研究中，我们希望将整个世界嵌入到思维向量中，我们将其称为world2vec（世界到向量）。”22

◆ 我们不能因此责怪词向量，它们只是从我们的语言中捕捉到了性别歧视以及其他歧视，因为，我们的语言的确反映了社会中的一些偏见。尽管词向量可能是无可指责的，但它们是现代自然语言处理系统（从语音识别到语言翻译）的关键组成部分，词向量的偏见可能会渗透在广泛使用的自然语言


第二十三章 12 机器翻译，仍然不能从人类理解的角度来理解图像与文字

◆ 深度学习时代的机器自动翻译是由大数据和快速计算造就的巨大成功。为了创建一个编码器-解码器网络，比如，将英语翻译成法语的，这些网络需要在超过3 000万对人工翻译的句子样本上进行训练。由长短期记忆单元组成，并且在大量数据集上进行训练的深度递归神经网络，已经成为现代自然语言处理系统的重要组成部分，不仅仅被用在谷歌翻译的编码器-解码器网络中，还被用在语音识别、情感分类以及我们将在下面看到的问答系统中。这些系统通常包含一些可以提高其表现的机制，比如同时前向和后向输入原始的句子，

◆ 对于机器翻译来说，主要的障碍在于：与语音识别系统的问题一样，机器翻译系统在执行任务时并没有真正“理解”它们正在处理的文本。18在翻译以及语音识别中，一直存在这样的问题

◆ 人类的水平，机器需要在多大程度上具备这种理解能力？侯世达认为：“翻译远比查字典和重新排列单词要复杂得多……要想做好翻译，机器需要对其所讨论的世界有一个心理模型

◆ 尽管微软说它的CaptionBot能够“理解”任何照片的内容，但事实正好相反：即便它们给出的字幕是正确的，这些系统也无法从人类的角度来理解图像。当我给微软的CaptionBot看第04章开头的那张照片时，系统的输出是：一位男士抱着一条狗。还算对吧，除了“男士”的部分……令人更遗憾的是，这段描述漏掉了照片中关键的、有价值的点，漏掉了通过图像对我们自身、对我们的体验、对我们关于世界的情感和知识进行表达的方式，也就是说，它漏


第二十四章 13 虚拟助理——随便问我任何事情

◆ ——《星际迷航：下一代》（Star Trek: The Next Generation）

◆ 谷歌前副总裁塔马·约书亚（Tamar Yehoshua）坦诚地认可了《星际迷航》中的计算机对谷歌设计面向未来的搜索引擎的影响：“我们的目标是《星际迷航》中那样的计算机，你可以和它说话，它理解你，并且它可以对你做出回应。”1IBM沃森的项目负责人大卫·费鲁奇（David Ferrucci）说：“《星际迷航》中的计算机功能、技术是IBM沃森的问答系统的核心灵感来源，《

◆ IBM应该开发一个能够把《危险边缘》游戏玩得足够好甚至能击败人类冠军的计算机程序。然后，IBM就能在一个关注度很高的电视节目上展示这个程序4。这个想法催生了由IBM自然语言研究员费鲁奇带领的一项努力了多年的项目，并最终创造了沃森——一个以IBM首任董事长托马斯·沃森的名字来命名的人工智能系统。


◆ 的知识数据库中快速搜索。正如《纽约时报》的一篇文章所述：“费鲁奇的团队为沃森建立了一个包含了数百万份文档的知识库——包括费鲁奇所说的书籍、所有类型的字典、主题词典、通俗分类、分类学、百科全书以及小说、圣经、戏剧等任何一种你能想象的可供掌握的参考资料……

◆ 电视上播出的《危险边缘》中，沃森给包括我在内的很多观众留下了一种不可思议的印象：它可以毫不费力并且流畅地理解和使用语言，对接收到的大多数主题都能以闪电般的速度来解读其中棘手的线索，并做出准确回应

◆ 是给公众一种印象：沃森虽然不是真正的人类，但和人类一样，它在积极地倾听和回应这些线索。可是公众不知道的是：沃森不使用语音识别，而是在主持人向人类参赛者朗读线索的同时接收每条线索的文本

◆ 沃森对线索的反应偶尔会破坏其类人形象，这并不仅仅是因为系统在某些线索上犯了错，所有的参赛者都会犯错，只是沃森的错误常常……不那么像人类会犯的错误。

◆ 沃森团队负责人费鲁奇回应道：“这台计算机并不知道缺了一条腿是一件很奇怪的事。”8沃森似乎也不明白这条线索——“2010年5

◆ 然而，沃森的胜利在很大程度上得益于它按抢答器的速度。


◆ 对观众说：“沃森是一名狂热的阅读者，每秒能吸收相当于100万本书的信息。

◆ 前，沃森才刚刚学会如何阅读和回答问题。现在，它就要从医学院毕业了。”当时，北卡罗来纳大学的癌

◆ 实际上，并不多。我只是了解了沃森在《危险边缘》中的表现。他们用大约一周的时间教沃森阅读了基本的医学文献，这并不是太难，然后沃森又用了大约一周的时间阅读了2 500万篇论文。”11

◆ 来，其中很多引用的是心怀不满的前雇员的言论，主要是指出IBM的一些高管和营销人员过分夸大了这项技术的应用前景。当然，

◆ 人工智能领域，承诺过高和交付不足是一个再常见不过的现象，IBM绝不是唯一的罪过方。只有在未来我们才能知道，在把人工智能应用于医疗康护、法律

◆ 2016年，斯坦福大学的自然语言研究团队设计了一个测试，并且很快就成了衡量机器阅读理解能力的标准，这就是斯坦福问答数据集（Stanford question answer dataset，SQuAD）

◆ 想要做对这道题，其实你并不需要读懂字里行间的意思，也不需要真正的推理，比起“阅读理解”，可能这项任务更准确的叫法应该是“答案提取”。答案提取对机器来说是一项很有用的技能，事实上，答案提取也正是Alexa、Siri以及其他数字助理软件所需要做的：将接收到的问题转换为一个搜索引擎查询序列，然后从搜索结果中提取答案。

◆ 事我们也不是第一次听说了。人工智能研究有一个惯用的套路：定义一个在细分领域中比较有用的任务，收集一个大型数据集来测试机器在该任务上的性能，对人类在该数据集上完成任务的能力进行一个有限的度量，然后，建立一场竞赛使得人工智能系统可以在该数据集上互相竞争，直到最终达到或超过人类的表现。相关各

◆ 人工智能专家说，阅读理解的真正要义在于阅读字里行间中相互关联的概念并进行推理，进而理解文本中有所暗示但又未具体给出的信息。”17我非常赞同这一观点。

◆ 2024/02/10发表想法

ChatGLM: 答案是A，桌子。根据句子1的描述，是因为桌子的宽度超过了门口的宽度，所以桌子无法穿过门口。

原文：问题：什么东西太宽了？

◆ 这些微型的语言理解测试被称为“威诺格拉德模式”（Winograd schemas），以最先提出这个想法的自然语言处理领域的先驱特里·威诺格拉德（Terry Winograd）的名字命名22。威诺格拉德模式被精确设计为对人类而言很简单，但对计算机而言却很棘手。

◆ 个自然语言处理研究团队已经试验了多种不同的方法来回答威诺格拉德模式测试题。在我写下这部分内容的时候，程序的最佳性能表现是：在一组约有250个问题的威诺格拉德模式测试集上达到了大约61%的正确

◆ 想象某个人，通过收音机广播发布了一段音频，对坐在家中的你而言，它是令人愉快的音乐，但你的家庭助理Alexa却将其理解为“跳转到某危险网站并下载计算机病毒”或“开始录音并把你听到的所有内容都发送到某危险网站上”。诸如此类可怕的情境，并非不可能发生。


◆ 有一点很重要：所有这些欺骗DNN的方法都是由“白帽”(42)从业者开发的，他们开发这种潜在的攻击方式，并将其发表到公开文献上，目的是让业界意识到这些漏洞，并推动业界研发相应的防御技术。另外，“黑帽”攻击者是一批试图欺骗已部署的系统以达到其邪恶目的的黑客，他们不会公开他们的攻击手段，因此系统中可能会存在许多我们没有意识到的其他类型的漏洞。据我所知，到目前为止，真实世界中还没有发生过针对深度学习系统的攻击，但我想这也只是时间问题。


◆ 在我看来，完全从在线数据中学习、基本上没有理解其所处理语言的机器，完全不可能达到人类在翻译、阅读理解等方面的水平。语言依赖于人们的常识和对世界的理解：半熟的汉堡包不是烤煳了的；一个太宽的桌子无法穿过门口；如果你把一个瓶子里的水全都倒出来，瓶子就会因此变空。语言也依赖于我们对所交流的对象的常识：如果一个人想要一个做得半熟的汉堡包，但却得到一个烤煳了的，那么这个人会不高兴的；如果一个人说一部电影“对我来说太黑暗了”，那么这个人并不喜欢这部电影。虽然机器的自然语言处理已经取得

◆ 阅读理解的关键不仅在于“提取答案”，还在于“具备常识”


第二十五章 第五部分 常识——人工智能打破意义障碍的关键

◆ 常识——人工智能打破意义障碍的关键

◆ 1．直觉　由

◆ 2．模拟　

◆ 3．隐喻　

◆ ．抽象与类比

◆ ．反思


第二十六章 14 正在学会“理解”的人工智能

◆ “我想知道人工智能是否以及何时能打破通向意义的障碍。”1每次在思考人工智能的未来时，我就会回想起由数学家兼哲学家吉安-卡洛·罗塔提出的这个问题。“意义的障碍”（barrier of meaning）这一短语完美地捕捉到了贯穿于全书的一个思想：人类能够以某种深刻且本质的方式来理解他们面对的情境，然而，目前还没有任何一个人工智能系统具备这样的理解力。

◆ 这一理解力的缺乏主要表现在以下方面：非人类式错误、难以对所学到的内容进行抽象和迁移、对常识的缺乏、面对对抗式攻击时所呈现出的脆弱性等。人工智能和人类水平智能之间的“意义的障碍”至今仍然存在。

◆ 孩提时代，我们人类学习了大量关于世界上的物体如何运转的知识，在我们成年后，就完全将其视为理所当然，甚至意识不到自己具备这些知识。如果你推一个物体，它就会向前移动，除非它太重或者受到其他物体的阻挡；如果你扔下一个物体，它会落下，然后在接触到地面时会停住、弹起来或者破裂；

◆ 心理学家为此创造了术语“直觉物理学”（intuitive physics）来描述人类对物体及其运转规则所具有的基本知识。当还是孩童的时候，我们还发展出了“直觉生物学”（intuitive biology）的概念，用以区分生命体和非生命体。例如，任何一个小孩都明白，与婴儿车不同，图14-1中的狗能够自主移动或拒绝移动。我们有这样的直觉：狗和人类一样能听能看，它将鼻子贴在地面上是为了嗅某些东西。
由于我们人类是一种典型的社会型物种，从婴儿时期开始我们逐步发展出了直觉心理：感知并预测他人的感受、信念和目标的能力。例如，你能够从图14-1中了解到以下信息：图中的女士想要与她的孩子和狗一起穿过马路；她不认识迎面走来的男士，也不害怕他；她的注意力正集中在手机通话上；她希望同行的车辆能够为她让道，以及当她注意到车辆与她相距太近时，她会感到吃惊和害怕。
直觉知识的这些核心主体构成了人类认知发展的基石，支撑着学习和思考的方方面面。例如，我们能够从少数案例中学习到新的概念，并进行泛化，因此，我们才拥有了快速理解类似于图14-1中所示的情境并决定采取何种应对措施的能力。4

◆ 简而言之，你拥有心理学家所说的关于世界之重要方面的“心智模型”，这个模型基于你掌握的物理学和生物学上的事实、因果关系和人类行为的知识。这些模型表示的是世界是如何运作的，使你能够从心理上模拟相应的情况。神经科学家还不清楚这种心智模型或运行在其之上的心智模拟，是如何从数十亿相互连接的神经元的活动中产生的。一些著名的心理学家提出：一个人对概念和情境的理解正是通过这些心智模拟来激活自己之前的亲身经历，并想象可能需要采取的行

◆ 要理解一个情境，其关键在于要能够利用心智模型来想象不同可能的未来。6

◆ 心理学家劳伦斯·巴斯劳（Lawrence Barsalou）是“理解即模拟”（understanding as simulation）假说最为知名的支持者之一。在他看来，我们对于我们所遇到的情境的理解包含在我们在潜意识里执行的心智模拟中。此外，巴斯劳提出，这种心智模拟同样构成了我们对于那些我们并未直接参与其中的情境的理解，比如我们看到的、听到的或读到的。巴斯劳写道：“当人们理解一段文本时，他们构建模拟来表征其感知、运动和情感等内容。模拟似乎是意义表达的核心

◆ 对于像“真相”“存在”“无限”等这类非常抽象的概念，我们是如何理解的呢？巴斯劳和他的同事们几十年来一直主张：即便是最为抽象的概念，我们也是通过对这些概念所发生的具体场景进行心智模拟来理解的。

◆ 根据巴斯劳的观点，我们使用对感觉-运动（sensory-motor）状态的重演（即模拟）来进行概念处理，并以此来表征其所属类别，即使是对最抽象的概念也是如此8。令人惊讶的是（至少对我来说）：这一假说最具说服力的证据来自对隐喻的认知研

◆ 的英语老师给我们列举了一些隐喻的例子，包括莎士比亚最著名的诗句：
“那边窗户里亮起的是什么光？那是东方，朱丽叶就是太阳。”
“人生不过是一个行走的影子，一个舞台上指手画脚的拙劣的伶人，登场片刻，就在无声无息中悄然退下。”
我当时的认识是：隐喻只不

◆ 读了由语言学家乔治·莱考夫（George Lakoff）(44)和哲学家马克·约翰逊（Mark Johnson）合著的《我们赖以生存的隐喻》（Metaphors We Live By）10一书，之后，我对隐喻的理解完全改变了。莱考夫和约翰逊的观点是：不仅仅是我们的日常语言中充斥着我们意识不到的隐喻，我们对基本上所有抽象概念的理解都是通过基于核心物理知识的隐喻来实现的。莱考夫和约翰逊引用了大量的语言示例来证明他们的论点，展示了我们如何用具体的物理概念来概念化诸如时间、爱、悲伤、愤怒和贫穷等抽象概念。

◆ 如时间。例如，我们经常会说：你“花费”或“节省”时间；你经常没有足够的时间来“花费”；有时你“花费”的时间是“值得的”，而且你已经合理地“使用”了时间；你可能认识一个在“借用的时间”(45)里活着的人。
类似

◆ 更进一步说，我们通常使用物理学中温度的概念来对社会交往概念化，比如，“我受到了热烈的欢迎”“她冷冰冰地凝视着我”“他对我很冷淡”。这些说法是如此根深蒂固，以至于我们根本没有意识到自己在以隐喻的方式讲话。莱考夫和约翰逊提出的这些隐喻揭示了我们对概念进行理解的物理基础这一主张，支持了巴斯劳的人们通过构建源自我们核心知识的心智模型的模拟来进行理解的理论。

◆ 心理学家通过许多有趣的实验探讨了上述想法。一组研究人员指出：不管一个人感受到的是身体上的温暖还是社交上的“温暖”，激活的似乎都是大脑的相同区域。为了研究这种可能的心理影响，研究人员对一组志愿者进行了接下来的实验。每位被试都由一名实验人

◆ 此外，物理和社交范畴的“温度”之间这一连接的反向似乎也成立。其他研究组的心理学家发现：“温暖”或“寒冷”的社交经历也会导致被试感受到物理层面的温暖或寒冷12。

◆ 劳、莱考夫和约翰逊的观点：我们通过核心物理知识来理解抽象概念。如果物理意义上的“温暖”概念在心理上被激活，例如，通过手持一杯热咖啡，这也会激活更抽象、隐喻层面上的“温暖”概念，就像评价一个人的性格的实验那样，并且反之亦然。


◆ 如果我们对概念和情境的理解是通过构建心智模型进行模拟来实现的，那么，也许意识以及我们对自我的全部概念，都来自我们构建并模拟自己的心智模型的能力。我不仅能在心智上模拟打着电话过马路的情境，还能在心智上模拟自己的这种想法，并预测自己接下来可能会想什么，也就是说，我们有一个关于自己心智模型的模型。为模型建构模型，模拟我们的模拟——为什么不可以呢？就像对温暖的物理感知，能够激活对温暖的隐喻感知，并且反之亦然，我们拥有的与物理感觉相关的概念可能会激活关于自我的抽象概念

◆ 后者通过神经系统的反馈，产生一种对自我的物理感知，你也可以将这里的“自我”称为意识。这种循环因果关系类似于侯世达所说的意识的“怪圈”：“符号和物理层面相互作用，并颠倒了因果关系，符号似乎拥有了自由意志，并获得了推动粒子运动的自相矛盾的能力。

◆ 到目前为止，我从心理学角度描述了人类与生俱来的，或在生命早期获得的核心直觉知识，以及这些知识如何成为构建了我们的各种观念的心智模型的基础。构建和使用这些心智模型依赖于两种基本的人类本能：抽象和类比。
抽

◆ 我提及这一想象出来的家长日记的目的是，阐述一些关于抽象和类比的重要观点。从某种形式上来说，抽象是我们所有概念的基础，甚至从最早的婴儿时期就开始了。像是在不同的光照条件、角度、面部表情以及不同的发型等条件下识别出母亲的面庞，这样简单的事情，与识别一种音乐风格，或是做出一个有说服力的法律上的类比，是同样的抽象的壮举

◆ 正如侯世达和他的合著者、心理学家伊曼纽尔·桑德尔（Emmanuel Sander）在《表象与本质》中所阐述的：“没有概念就没有思想，没有类比就没有概念。”17

◆ 我们的概念在大脑中被编码为可运行（即模拟）的心智模型，以预测在各种情境下可能发生的事情，或者给定任一我们能想到的变化之后可能会发生什么。我们大脑中的概念，从简单的词语到复杂的情境，都是通过抽象和类比习得的。

◆ 事实上，很多人已经注意到“理解”和“意义”等术语只是我们用来当作占位符的定义不明的术语，更不用说意识了，因为目前我们还没有用来讨论大脑中究竟发生了什么的准确的语言或理论

◆ 相信）、‘know’（知道）、‘mean’（意味着）这样的词语在日常生活中变得很常用，但严格来说，它们的定义似乎太过粗糙，以至于无法支撑强有力的理论……就如同目前的‘self’（自我）或‘understand’（理解）这样的词语对我们而言一样，它们尚处于通往更完善的概念的起步阶段。”明斯基继续指出：“我们对这些概念的混淆，源于传统思想不足以解决这一极度困难的问题……我们现在还处在关于心智的一系列概念的形成期。”18


第二十七章 15 知识、抽象和类比，赋予人工智能核心常识

◆ 坚持为机器人工编写常识的最著名和持续时间最久的是道格拉斯·雷纳特（Douglas Lenat）的“Cyc”项目。雷纳特当时是斯坦福大学人工智能实验室的一名博士生，后来晋升为该实验室的教授，由于开发了模拟人类发明新概念（特别是在数学领域）的程序，他在20世纪70年代人工智能领域的研究群体中赢得了名声1。经过对这一课题10多年的研究，雷纳特得出了一个结论：要想令人工智能实现真正进步，就需要让机器具备常识。因此，他决定创建一个庞大的关于世界的事实和逻辑规则的集合，并且使程序能够使用这些逻辑规则来推断出它们所需要的事实。1984年，雷纳特放弃了他的学术职位，创办了一家名为“Cycorp”的公司来实现这一目标。
“Cyc”这一名字

◆ Cyc的论断由Cycorp的员工手动编码，或由系统从现有的论断出发，通过逻辑推理编码到集合中。3那么究竟需要多少论断才能获得人类的常识呢？在2015年的一次讲座中，雷纳特称目前Cyc中的论断数量为1 500万，并猜测说：“我们目前大概拥有了最终所需的论断数量的5%左右。”4


◆ 到目前为止，Cyc还没有对人工智能的主流研究产生太大的影响。此外，一些人工智能研究人员尖锐地批评了这一项目。例如，华盛顿大学的人工智能教授佩德罗·多明戈斯（Pedro Domingos）评价Cyc是“人工智能历史上最臭名昭著的失败案例”7；麻省理工学院的机器人专家罗德尼·布鲁克斯稍微友善那么一点点，他说：“尽管Cyc是一次英勇的尝试，但它并未使得人工智能系统能够掌握对世界哪怕是一丁点儿简单的理解。”8


◆ 邦加德问题也挑战了人类迅速感知新概念的能力，问题18（见图15-2）是一个很好的例子。在这个问题中，左侧方框中的通识概念很难用语言表达，它就像是具有一个收缩的或类似于人类颈部的对象，但即便你在此之前从未想到过任何与之类似的对象，你也能在问题18中快速识别出来。类似地，在问题19（见图15-2）中，有一个新概念：左边是一个类似水平颈部的对象，而右边是一个具有垂直颈部的对象。抽象化新的、难以描述的概念真的是人类非常擅长的事情，但目前所有的人工智能系统都无法以任何通用的方式做到这点。

◆ 鉴于ConvNets在对象分类上的表现如此出色（你可以回想下我在第05章中描述的盛大的ImageNet“视觉识别挑战赛”上ConvNets的表现），那么，我们是否可以通过训练这样一个网络来解决邦加德问题呢？你可以假设将一个邦加德问题建构为ConvNets的一种分类问题，如图15-3中所示：左侧的6个方框可以被视为类别1中的训练样本，而右侧的6个方框是类别2中的训练样本。现在给系统一个新的测试样本，它应该被归为类别1还是类别2呢？

◆ 现代人工智能以深度学习为主导，以DNN、大数据和超高速计算机为三驾马车，然而，在追求稳健和通用的智能的过程中，深度学习可能会碰壁——重中之重的“意义的障碍”。在本章中，我展示了人工智能为打破这一障碍所做的一些努力，我们可以看到研究人员（包括我自己）是如何为计算机灌输常识，并尝试赋予它们类似于人类的抽象和类比能力的。

◆ 卡帕西是一名深度学习和计算机视觉领域的专家，他目前在指导特斯拉的人工智能的相关工作。卡帕西在其发表的一篇题为《计算机视觉和人工智能的现状：我们真的，真的相距甚远》的文章中24，描述了自己作为一名计算机视觉研究人员对一张特定照片的反应（见图15-6）。卡帕西指出，我们人类会发现这张照片非常幽默，那么，问题来了：“一台计算机需要具备什么样的知识才能像你我一样去理解这张照片？”

◆ 我几乎可以肯定的是：我们可能需要进一步探索“具身”（embodiment）(47)这一概念。构建像我们这样能够理解各种场景的计算机的唯一方法，就是让它们接触到我们在这么多年来所拥有的结构化的和暂时的经验、与世界互动的能力，以及一些在我思考它应具备何种能力时几乎都无法想象的神奇的主动学习和推理的能力。
在17


第二十八章 结语

◆ 这取决于你怎么定义“自动驾驶”。美国国家公路交通安全管理局为车辆定义了6个自动等级1。我在此转述如下：
0级：人类驾驶员执行全部的驾驶任务。
1级：车辆能够偶尔通过控制方向盘或车速来对人类驾驶员提供支持，但不能同时进行。
2级：在某些情境下（通常是在高速公路上），车辆可以同时控制方向盘和车速。人类驾驶员必须时刻保持高度注意力，监控驾驶环境，并完成驾驶所需的其他行为，如变换车道、驶离高速公路、遇到红绿灯时停车、为警车让行等。
3级：在某些特定情境下车辆可以执行所有的驾驶行为，但是人类驾驶员必须随时保持注意力，并随时准备在必要时收回驾驶控制权。
4级：在特定情境下，车辆能够完成所有的驾驶行为，人类不需要投入注意力。
5级：车辆可以在任何情境下完成所有驾驶行为。人类只是乘客，并且完全不需要参与驾驶。

◆ 主要的障碍是我在第06章中描述的那些长尾效应（边缘案例），即车辆没有接受过训练的情境，通常，它们单独发生的可能性很小，但当自动驾驶车辆被普及时，整体来看，这些情况就会频繁发生。正如我所描述的，人类驾驶员会使用常识来处理这些事件，即通过将新遇到的情境与已了解的情境进行类比的方式来理解、预测并处理新的情境。
车辆的完全自主也需要我在

◆ 。一句值得记住的格言是：对于一项复杂的技术项目，完成其前90%的工作往往只需要花费10%的时间，而完成最后10%则需要花费90%的时间

◆ 当然，那些令人讨厌的喜欢恶作剧的人也包含在地理围栏内。吴恩达建议，行人需要学会在身处自动驾驶汽车的周围时表现得更加可预测：“我们需要告诉人们的是，请遵守法律并多加体谅。”4吴恩达的自动驾驶公司Drive.ai已经推出了一支能够在特定的地理围栏内接送乘客的完

◆ 的猜测是不会，至少近期不会。马文·明斯基的“容易的事情做起来难”这句格言仍然适用于人工智能的大部分领域，并且许多人类的工作对于计算机或机器人而言可能比我们想象的要困难得多。
毫无疑问，人工智能系统将在某些工作上取代人类，它们已经取代了部分的人类工作，其中很多都给社会带来了益处。目前没有人知道人工智能会在总体上对就业产生什么样的

◆ 西姆斯的程序的创造力来自人与计算机的合作：计算机生成原始的艺术作品，然后生成其后续变体，而人类对计算机生成的作品做出评判，其依据来自人类对抽象艺术的理解。计算机对抽象艺术并没有任何理解力，因此它本身并不具有创造性。


◆ 科普创造EMI的初衷是：将其作为他私人的“作曲小助手”。科普一直对运用随机性创作音乐的悠久传统十分着迷。一个著名的例子是莫扎特和18世纪的其他音乐家常玩的所谓的“音乐骰子游戏”——创作者把一曲音乐切分成很多小片段，然后通过掷骰子来选择该片段在新乐曲中的位置

◆ 我们所知道的是，通用的、人类水平的人工智能需要人工智能研究人员数十年来一直努力去理解和再现的能力，比如，对常识的理解、抽象和类比等，但这些方面的能力被证明是非常难以获得的。而且，其他一些重大的问题仍然存在：通用人工智能将需要意识吗？有对自我的感知吗？能感受情绪吗？具有生存的本能和对死亡的恐惧吗？需要一具躯体吗？正如我在前文引用的明斯基的那句话：“我们现在还处在关于心智的一系列概念的形成期。

◆ 我以侯世达对人工智能之最新进展感到惊慌的一段见闻作为本书的开始，但在很大程度上，令他感到恐惧的是完全不同的事情。侯世达担心的是：人类的认知能力和创造力变得如此轻易就能被人工智能程序习得，从而使得他最为珍视的基于人类思想的崇高创作，如肖邦的音乐，可被像是EMI那样的人工智能程序使用的那套肤浅的算法替代。侯世达感叹道：“如果这种无限微妙、复杂且情感深厚的思想会被一块小小的芯片所简化，这会摧毁我对人性的理解。”侯世达同样对库兹韦尔关于即将到来的奇点的预测而感到困扰，他担心如果库兹韦尔的这种预测从任何一方面来说是正确的，那么我们将被取代，我

◆ 经济学家塞德希尔·穆来纳森（Sendhil Mullainathan）(50)在撰写关于人工智能之危险的文章时，在他提出的“尾部风险”（tail risk）的概念中引用了我在第06章中描述过的长尾效应：
我们应该感到害怕，不是害怕机器太智能，而是害怕机器做出一些它们没有能力做出的决策。相比于机器的“智能”，我更害怕机器的“愚笨”。机器的愚笨会创造一个尾部风险。机器可以做出很多好的决策，然后某天却会因为在其训练数据中没有出现过的一个尾部事件而迅速失灵，这就是特定智能和通用智能的区别20。


◆ 或者正如人工智能研究人员佩德罗·多明戈斯所说的那段令人印象深刻的话：“人们担心计算机会变得过于聪明并接管世界，但真正的问题是计算机太愚蠢了，并且它们已经接管了世界

